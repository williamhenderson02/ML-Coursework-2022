{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# - Notes for use to avoid confusion :)\n",
    "\n",
    "\n",
    "#Not all cells work together. For example if you run the cell that deals with missing values by removing the entire row\n",
    "#or removing all columns you will not be able to use the method to predict null values because the entries will be gone.\n",
    "\n",
    "#So in order to predict the missing values after using the code cells that remove them you simply have to first run the code cell\n",
    "#which reads the original data again\n",
    "\n",
    "#Websites:\n",
    "    #preporcessing methods outline - https://blog.ml.cmu.edu/2020/08/31/2-data-exploration/\n",
    "    #outliers simple - https://analyticsindiamag.com/how-to-detect-and-treat-outliers-in-categorical-data/\n",
    "    #pca collinearity removal/heatmap - https://towardsdatascience.com/how-do-you-apply-pca-to-logistic-regression-to-remove-multicollinearity-10b7f8e89f9b#:~:text=PCA%20in%20action%20to%20remove%20multicollinearity&text=PCA%20(Principal%20Component%20Analysis)%20takes,effectively%20eliminate%20multicollinearity%20between%20features.\n",
    "    #vif - https://towardsdatascience.com/how-to-remove-multicollinearity-using-python-4da8d9d8abb2\n",
    "    #pca 2D - https://towardsdatascience.com/principal-component-analysis-pca-from-scratch-in-python-7f3e2a540c51\n",
    "    #pca 3D - https://drzinph.com/pca-visualized-with-3d-scatter-plots/\n",
    "    #tsne -https://builtin.com/data-science/tsne-python\n",
    "    #umap - https://blog.ml.cmu.edu/2020/08/31/2-data-exploration/\n",
    "    #automatic outlier detection - https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/\n",
    "    #3D tsne and umap -  https://plotly.com/python/t-sne-and-umap-projections/#project-data-into-3d-with-tsne-and-pxscatter3d\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kai Heale\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#missing values have value ? all for attribute 11\n",
    "\n",
    "#either edible, poisonous or unknown. Unknowm and poisonous grouped together\n",
    "\n",
    "#to deal with missing values use 'classifier' or 'regressor' based on values that arent missing to predict missing values in\n",
    "#preprocessing. Be careful that vlaues using to predict arent overfitted. Compare to other methods such as removing entire attribute\n",
    "#or giving deafult/mean value\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edibility                 2\n",
      "capShape                  6\n",
      "capSurface                4\n",
      "capColor                 10\n",
      "bruises                   2\n",
      "odor                      9\n",
      "gillAttachment            2\n",
      "gillSpacing               2\n",
      "gillSize                  2\n",
      "gillColor                12\n",
      "stalkShape                2\n",
      "stalkRoot                 4\n",
      "stalkSurfaceAboveRing     4\n",
      "stalkSurfaceBelowRing     4\n",
      "stalkColorAboveRing       9\n",
      "stalkColorBelowRing       9\n",
      "veilType                  1\n",
      "veilColor                 4\n",
      "ringNumber                3\n",
      "ringType                  5\n",
      "sporePrintColor           9\n",
      "population                6\n",
      "habitat                   7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# read contents of data file\n",
    "file = pd.read_csv(\"agaricus-lepiota.data\", header = None)\n",
    "\n",
    "# create list to be used as headers\n",
    "features = ['edibility', 'capShape', 'capSurface', 'capColor', 'bruises', 'odor', \n",
    "            'gillAttachment', 'gillSpacing', 'gillSize', 'gillColor', \n",
    "            'stalkShape', 'stalkRoot', 'stalkSurfaceAboveRing', 'stalkSurfaceBelowRing', \n",
    "            'stalkColorAboveRing', 'stalkColorBelowRing', 'veilType', 'veilColor', \n",
    "            'ringNumber', 'ringType', 'sporePrintColor', 'population', 'habitat']\n",
    "\n",
    "#convert '?' to NaN\n",
    "file.replace({'?': np.nan}, inplace=True)\n",
    "\n",
    "# converting data frame to csv\n",
    "file.to_csv(\"agaricus-lepiota.csv\", header=features, index=False)\n",
    "\n",
    "data = pd.read_csv(\"agaricus-lepiota.csv\")\n",
    "\n",
    "#we can drop veilType as all entries are the same so cannot be used to predict\n",
    "print(data.nunique())\n",
    "data = data.drop('veilType', axis = 1).reset_index(drop=True)\n",
    "features.remove('veilType')\n",
    "\n",
    "#print(data['gillColor'].value_counts())\n",
    "\n",
    "#result = data.head(10)\n",
    "#print(data)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes column with missing values which in our data is only stalkRoot\n",
    "#one way to deal with missing values\n",
    "print(data.shape)\n",
    "\n",
    "data = data.drop('stalkRoot', axis = 1).reset_index(drop=True)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data.to_csv(\"agaricus-lepiota-no-stalkRoot.csv\")\n",
    "\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes all rows that have missing values\n",
    "print(data.shape)\n",
    "\n",
    "data = data.dropna(axis = 0).reset_index(drop=True)\n",
    " \n",
    "#shows we lose alot of data as 2480 rows lost\n",
    "#bad way of handling missing values\n",
    "print(data.shape)\n",
    "\n",
    "data.to_csv(\"agaricus-lepiota-NaN-removed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use label encoding on all features that are categorical\n",
    "#OneHot encoding not applicable as there are a high number of categories\n",
    "le = LabelEncoder()\n",
    "\n",
    "data['edibility'] = le.fit_transform(data['edibility'])\n",
    "data['capShape'] = le.fit_transform(data['capShape'])\n",
    "data['capSurface'] = le.fit_transform(data['capSurface'])\n",
    "data['capColor'] = le.fit_transform(data['capColor'])\n",
    "data['bruises'] = le.fit_transform(data['bruises'])\n",
    "data['odor'] = le.fit_transform(data['odor'])\n",
    "data['gillAttachment'] = le.fit_transform(data['gillAttachment'])\n",
    "data['gillSpacing'] = le.fit_transform(data['gillSpacing'])\n",
    "data['gillSize'] = le.fit_transform(data['gillSize'])\n",
    "data['gillColor'] = le.fit_transform(data['gillColor'])\n",
    "data['stalkShape'] = le.fit_transform(data['stalkShape'])\n",
    "data['stalkRoot'] = le.fit_transform(data['stalkRoot'])\n",
    "data['stalkSurfaceAboveRing'] = le.fit_transform(data['stalkSurfaceAboveRing'])\n",
    "data['stalkSurfaceBelowRing'] = le.fit_transform(data['stalkSurfaceBelowRing'])\n",
    "data['stalkColorAboveRing'] = le.fit_transform(data['stalkColorAboveRing'])\n",
    "data['stalkColorBelowRing'] = le.fit_transform(data['stalkColorBelowRing'])\n",
    "data['veilColor'] = le.fit_transform(data['veilColor'])\n",
    "data['ringNumber'] = le.fit_transform(data['ringNumber'])\n",
    "data['ringType'] = le.fit_transform(data['ringType'])\n",
    "data['sporePrintColor'] = le.fit_transform(data['sporePrintColor'])\n",
    "data['population'] = le.fit_transform(data['population'])\n",
    "data['habitat'] = le.fit_transform(data['habitat'])\n",
    "\n",
    "data.to_csv(\"agaricus-lepiota-encoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       119\n",
      "           2       1.00      1.00      1.00       239\n",
      "           3       1.00      1.00      1.00        47\n",
      "\n",
      "    accuracy                           1.00      1129\n",
      "   macro avg       1.00      1.00      1.00      1129\n",
      "weighted avg       1.00      1.00      1.00      1129\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       724\n",
      "           1       1.00      1.00      1.00       119\n",
      "           2       1.00      1.00      1.00       239\n",
      "           3       1.00      1.00      1.00        47\n",
      "\n",
      "    accuracy                           1.00      1129\n",
      "   macro avg       1.00      1.00      1.00      1129\n",
      "weighted avg       1.00      1.00      1.00      1129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict missing values for stalkRoot\n",
    "NaN_predict = data.drop('edibility', axis = 1).reset_index(drop=True)\n",
    "\n",
    "NaN_train_data = NaN_predict[NaN_predict['stalkRoot']!= 4].copy()\n",
    "NaN_test_data = NaN_predict[NaN_predict['stalkRoot'] == 4].copy()\n",
    "\n",
    "NaN_X_train = NaN_train_data.drop('stalkRoot', axis = 1).reset_index(drop=True)\n",
    "NaN_y_train = NaN_train_data['stalkRoot']\n",
    "\n",
    "NaN_X_test = NaN_test_data.drop('stalkRoot', axis = 1).reset_index(drop=True)\n",
    "\n",
    "###############################################################################################################################\n",
    "#This code further breaks the data down into training and test sets comprising of rows that have no missing values\n",
    "#Allows us to run models and check how accurately they can predict the missing values then choose an appropriate one\n",
    "#In this case both Random Forest and Support Vector Classification predict that exact same values for 'stalkRoot' so either can be used\n",
    "#Both have 100% accuracy in predicitng 'stalkRoot' so we know when we predict the missing values they will most likely be correct.\n",
    "X_train, X_test, y_train, y_test = train_test_split(NaN_train_data, NaN_train_data['stalkRoot'], test_size=0.2,random_state=42)\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "svm = SVC()\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "rfr_pred = rfr.predict(X_test)\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "rfr_rounded = (np.rint(rfr_pred)).astype(int)\n",
    "\n",
    "svm_rounded = (np.rint(svm_pred)).astype(int)\n",
    "\n",
    "different = []\n",
    "\n",
    "for i in range(len(rfr_rounded)):\n",
    "    if rfr_rounded[i] != svm_rounded[i]:\n",
    "        different.append(rfr_rounded[i], svm_rounded[i])\n",
    "\n",
    "print(len(different))\n",
    "\n",
    "print(classification_report(y_test,rfr_rounded))\n",
    "\n",
    "print(classification_report(y_test,svm_rounded))\n",
    "##############################################################################################################################\n",
    "\n",
    "rfc = RandomForestRegressor()\n",
    "\n",
    "rfc.fit(NaN_X_train,NaN_y_train)\n",
    "y_pred = rfc.predict(NaN_X_test)\n",
    "\n",
    "rounded_data = (np.rint(y_pred)).astype(int)\n",
    "NaN_test_data['stalkRoot'] = rounded_data\n",
    "\n",
    "NaN_test_data.to_csv(\"predicted-missing-values.csv\")\n",
    "\n",
    "frames = [NaN_train_data, NaN_test_data]\n",
    "treated_data = pd.concat(frames)\n",
    "treated_data.insert(0, column = 'edibility', value = data['edibility'])\n",
    "\n",
    "X = treated_data.drop('edibility', axis = 1).reset_index(drop=True)\n",
    "y = treated_data['edibility']\n",
    "\n",
    "data_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "treated_data.to_csv(\"full-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3    0.396825\n",
      "4    0.260317\n",
      "2    0.117460\n",
      "9    0.107937\n",
      "8    0.092063\n",
      "0    0.022222\n",
      "5    0.003175\n",
      "Name: capColor, dtype: float64, 5    0.387302\n",
      "2    0.374603\n",
      "0    0.060317\n",
      "8    0.057143\n",
      "3    0.047619\n",
      "1    0.041270\n",
      "7    0.031746\n",
      "Name: odor, dtype: float64, 3     0.212698\n",
      "2     0.196825\n",
      "0     0.177778\n",
      "5     0.126984\n",
      "4     0.104762\n",
      "7     0.098413\n",
      "10    0.057143\n",
      "9     0.022222\n",
      "11    0.003175\n",
      "Name: gillColor, dtype: float64, 7    0.609524\n",
      "6    0.200000\n",
      "4    0.079365\n",
      "0    0.060317\n",
      "3    0.047619\n",
      "5    0.003175\n",
      "Name: stalkColorAboveRing, dtype: float64, 7    0.625397\n",
      "6    0.184127\n",
      "4    0.079365\n",
      "0    0.073016\n",
      "3    0.034921\n",
      "5    0.003175\n",
      "Name: stalkColorBelowRing, dtype: float64, 1    0.285714\n",
      "2    0.273016\n",
      "3    0.222222\n",
      "7    0.212698\n",
      "5    0.003175\n",
      "4    0.003175\n",
      "Name: sporePrintColor, dtype: float64, 4    0.403175\n",
      "3    0.253968\n",
      "5    0.152381\n",
      "0    0.111111\n",
      "2    0.076190\n",
      "1    0.003175\n",
      "Name: population, dtype: float64, 1    0.444444\n",
      "0    0.295238\n",
      "4    0.142857\n",
      "2    0.063492\n",
      "3    0.050794\n",
      "5    0.003175\n",
      "Name: habitat, dtype: float64]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define outliers as values a category can take which is significantly more or less frequent than the others\n",
    "# this cell is purely exploratory and does not record the outliers themselves, only which categories contain them\n",
    "# only need to run this for visualisation, can skip and just run below cell to remove outliers\n",
    "\n",
    "threshold = 0.05 # decides relative frequency threshold, below which values are considered outliers\n",
    "contains_outliers = []\n",
    "num_values = data.nunique()\n",
    "\n",
    "# loop through categories and identify which contain outliers according to the above definitions\n",
    "for i in range(len(features)):\n",
    "    if num_values[i] > 2:\n",
    "        value_frequencies = data[features[i]].value_counts(normalize=True) # normalize parameter converts values to relative frequency\n",
    "\n",
    "        for j in range(len(value_frequencies)):\n",
    "            if value_frequencies.iloc[j] < threshold:\n",
    "                contains_outliers.append(value_frequencies)\n",
    "                break\n",
    "\n",
    "print(contains_outliers)\n",
    "\n",
    "# now display histogram\n",
    "for x in range(len(contains_outliers)):\n",
    "    plt.hist(contains_outliers[x], alpha = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 removed out of 8124 total entries.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# deletion method: remove all rows containing outliers\n",
    "\n",
    "total_entries = len(data)\n",
    "total_features = len(features)\n",
    "removed_entries = []\n",
    "total_removed_entries = 0\n",
    "num_values = data.nunique()\n",
    "features_num = 0 # start category\n",
    "\n",
    "frequency_threshold = 0.05 # define what relative frequency is the threshold to be considered an outlier\n",
    "outlier_threshold = 3 # define how many outliers makes an entry a candidate for deletion\n",
    "\n",
    "# loop through data and remove rows as outliers are detected\n",
    "for i in range(total_features):\n",
    "    if num_values[i] > 2: # features with 2 possible values cannot have outliers\n",
    "        value_frequencies = data[features[i]].value_counts(normalize=True) # relative frequencies of each value in a feature\n",
    "        outlier_values = []\n",
    "\n",
    "        # make list of which values are outliers\n",
    "        for j in range(len(value_frequencies)):\n",
    "            if value_frequencies.iloc[j] < frequency_threshold:\n",
    "                outlier_values.append(j)\n",
    "        \n",
    "        # if an entry contains an outlier value, remove it\n",
    "        entry_num = 0\n",
    "        while entry_num < (len(data) - 1):\n",
    "            num_outliers = 0\n",
    "            \n",
    "            for x in range(len(outlier_values)):\n",
    "                if data.at[entry_num, features[i]] == outlier_values[x]:\n",
    "                    num_outliers += 1\n",
    "                    break\n",
    "\n",
    "            if num_outliers >= outlier_threshold:\n",
    "                total_removed_entries += 1\n",
    "                removed_entries.append(data.loc[entry_num])\n",
    "                data = data.drop(index=entry_num).reset_index(drop=True)\n",
    "                \n",
    "            entry_num += 1\n",
    "\n",
    "print(total_removed_entries,\"removed out of\",total_entries,\"total entries.\")\n",
    "print(removed_entries)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variance inflation factor\n",
    "\n",
    "fig = plt.figure(figsize=(25, 20))\n",
    "sns.heatmap(X.corr(), annot=True)\n",
    "plt.savefig(\"Heatmap.png\")\n",
    "\n",
    "#as you can see from heatmap there are some fearutes with high correlation\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X.columns\n",
    "\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "\t\t\t\t\t\tfor i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data)\n",
    "\n",
    "features_to_drop = []\n",
    "\n",
    "for i in range(len(X.columns)):\n",
    "\tif vif_data[\"VIF\"][i] > 7:\n",
    "\t\tdrop = vif_data[\"VIF\"][i]\n",
    "\t\tfeatures_to_drop.append(vif_data[\"feature\"][i])\n",
    "\t\n",
    "uncorrelated_X = X.drop(features_to_drop, axis = 1).reset_index(drop=True)\n",
    "\n",
    "uncorrelated_X_scaled = StandardScaler().fit_transform(uncorrelated_X)\n",
    "\n",
    "#generally features with VIF > 5 get removed but we can experiment with slightly higher i.e > 7\n",
    "\n",
    "fig2 = plt.figure(figsize=(25, 20))\n",
    "sns.heatmap(uncorrelated_X.corr(), annot=True)\n",
    "plt.savefig(\"Heatmap2.png\")\n",
    "\n",
    "#as seen by second heatmap these have much less colinearality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualisation pca\n",
    "#a linear method so less complex than tsne thus takes much less time\n",
    "#not very useful to visualise our dataset I dont think as shown by the explained variance and scree plot\n",
    "pca = PCA(random_state=42)\n",
    "pca_features = pca.fit_transform(data_scaled)\n",
    "\n",
    "per_var = np.round(pca.explained_variance_ratio_*100, decimals = 1)\n",
    "print(per_var)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    "\n",
    "#to be seen on a 2D-plot we can only use PC1 and PC2 which gives us the highest explained variance but still very low\n",
    "#around 19% + 12% = 31% explained variance which is bad\n",
    "plt.bar(x= range(1,len(per_var)+1), height = per_var, tick_label = labels)\n",
    "plt.show()\n",
    "\n",
    "pca_df = pd.DataFrame({'pca_1': pca_features[:,0], 'pca_2': pca_features[:,1], 'label': treated_data['edibility']})\n",
    "print(pca_df)\n",
    "\n",
    "sns.scatterplot(x = 'pca_1', y = 'pca_2', hue = 'label', data = pca_df)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#PCA could be useful to reduce multicolinearality though instead of data visualisation\n",
    "#use the first 8 pc's to get about ~90% explained variance, 9 to get ~93%, 10 to get ~95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA 3D\n",
    "pca = PCA(n_components = 3, random_state=42)\n",
    "pca_features = pca.fit_transform(data_scaled)\n",
    "\n",
    "per_var = np.round(pca.explained_variance_ratio_*100, decimals = 1)\n",
    "print(per_var)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    "\n",
    "pca_df = pd.DataFrame({'pca_1': pca_features[:,0], 'pca_2': pca_features[:,1], 'pca_3': pca_features[:,2], 'label': treated_data['edibility']})\n",
    "\n",
    "edible = pca_df[pca_df['label'] == 0]\n",
    "poisonous = pca_df[pca_df['label'] == 1]\n",
    "\n",
    "colors=['b', 'r'] \n",
    "\n",
    "fig = plt.figure(1)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "p1 = ax.plot(edible['pca_1'], \n",
    "             edible['pca_2'], \n",
    "             edible['pca_3'], \n",
    "             'o', color=colors[0],                                 \n",
    "             alpha = 0.6, label='edible',                           \n",
    "             markersize=3, \n",
    "             markeredgecolor='black',\n",
    "             markeredgewidth=0.1)\n",
    "\n",
    "p2 = ax.plot(poisonous['pca_1'], \n",
    "             poisonous['pca_2'], \n",
    "             poisonous['pca_3'], \n",
    "             'o', color=colors[1],                                 \n",
    "             alpha = 0.6, label='poisonous',                           \n",
    "             markersize=3, \n",
    "             markeredgecolor='black',\n",
    "             markeredgewidth=0.1)\n",
    "\n",
    "ax.set_xlabel('PCA-1, ' +  str(round(pca.explained_variance_ratio_[0]*100,2)) + '% Explained', fontsize=7)\n",
    "ax.set_ylabel('PCA-2, ' +  str(round(pca.explained_variance_ratio_[1]*100,2)) + '% Explained', fontsize=7)\n",
    "ax.set_zlabel('PCA-3, ' +  str(round(pca.explained_variance_ratio_[2]*100,2)) + '% Explained', fontsize=7)\n",
    "#z label wont work not sure why its 10.7% explained\n",
    "\n",
    "fig.legend(fontsize = 'x-small', loc='upper center', markerscale=2)\n",
    "plt.autoscale()\n",
    "plt.rcParams[\"figure.dpi\"] = 1000                            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualisation t-sne 2D\n",
    "#unlike pca its not linear so much more complex and better for our data I think\n",
    "#result of t-sne greatly affected by 'perplexity' hyperparameter\n",
    "#try perplexity values in the range 5-100 default is 30. Higher perplexity takes longer but may be better\n",
    "n_components = 2\n",
    "tsne = TSNE(n_components, perplexity=50)\n",
    "tsne_features = tsne.fit_transform(data_scaled)\n",
    "\n",
    "tsne_df = pd.DataFrame({'tsne_1': tsne_features[:,0], 'tsne_2': tsne_features[:,1], 'label': treated_data['edibility']})\n",
    "\n",
    "sns.scatterplot(x = 'tsne_1', y = 'tsne_2', hue = 'label', data = tsne_df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D tsne using plotly\n",
    "n_components = 3\n",
    "tsne = TSNE(n_components, perplexity=50, random_state=42)\n",
    "tsne_features = tsne.fit_transform(data_scaled)\n",
    "\n",
    "treated_data[\"edibility\"] = treated_data[\"edibility\"].astype(str)\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    tsne_features, x=0, y=1, z=2,\n",
    "    color=treated_data['edibility'], labels={'color': 'edibility'}\n",
    ")\n",
    "fig.update_traces(marker_size=8)\n",
    "fig.show()\n",
    "\n",
    "\"\"\"tsne = tsne = TSNE(n_components, perplexity=50, random_state = 42)\n",
    "tsne_features = tsne.fit_transform(uncorrelated_X_scaled)\n",
    "\n",
    "treated_data[\"edibility\"] = treated_data[\"edibility\"].astype(str)\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    tsne_features, x=0, y=1, z=2,\n",
    "    color=treated_data['edibility'], labels={'color': 'edibility'}\n",
    ")\n",
    "fig.update_traces(marker_size=8)\n",
    "fig.show()\"\"\"\n",
    "\n",
    "treated_data[\"edibility\"] = treated_data[\"edibility\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualisation UMAP\n",
    "#UMAP works very similarly to tsne but get more efficient for higher volumes of data\n",
    "#result greatly affected by n_neighbors and min_dist hyperparameters\n",
    "#for n_neighbors try range 5-100 and min_dist 0.1-1\n",
    "fit = umap.UMAP(\n",
    "    n_neighbors=50,\n",
    "    min_dist=0.25,\n",
    "    n_components=2,\n",
    "    metric = 'correlation',\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "umap_features = fit.fit_transform(data_scaled)\n",
    "\n",
    "umap_df = pd.DataFrame({'umap_1': umap_features[:,0], 'umap_2': umap_features[:,1], 'label': treated_data['edibility']})\n",
    "\n",
    "sns.scatterplot(x = 'umap_1', y = 'umap_2', hue = 'label', data = umap_df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UMAP 3D using plotly\n",
    "fit = umap.UMAP(\n",
    "    n_neighbors=50,\n",
    "    min_dist=0.25,\n",
    "    n_components=3,\n",
    "    metric = 'correlation',\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "umap_features = fit.fit_transform(data_scaled)\n",
    "\n",
    "treated_data[\"edibility\"] = treated_data[\"edibility\"].astype(str)\n",
    "\n",
    "fig_3d = px.scatter_3d(\n",
    "    umap_features, x=0, y=1, z=2,\n",
    "    color=treated_data['edibility'], labels={'color': 'edibility'}\n",
    ")\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "\n",
    "fig_3d.show()\n",
    "\n",
    "\n",
    "\"\"\"fit = umap.UMAP(\n",
    "    n_neighbors=50,\n",
    "    min_dist=0.25,\n",
    "    n_components=3,\n",
    "    metric = 'correlation',\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "umap_features = fit.fit_transform(uncorrelated_X_scaled)\n",
    "\n",
    "treated_data[\"edibility\"] = treated_data[\"edibility\"].astype(str)\n",
    "\n",
    "fig_3d = px.scatter_3d(\n",
    "    umap_features, x=0, y=1, z=2,\n",
    "    color=treated_data['edibility'], labels={'color': 'edibility'}\n",
    ")\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "\n",
    "fig_3d.show()\"\"\"\n",
    "\n",
    "treated_data[\"edibility\"] = treated_data[\"edibility\"].astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7438fcacdeb9fab963aae1492df335fc677df15640654dd4bab57d8a02162c47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
