{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Websites__<br>\n",
    "    preprocessing methods outline - https://blog.ml.cmu.edu/2020/08/31/2-data-exploration/<br>\n",
    "    outliers - https://analyticsindiamag.com/how-to-detect-and-treat-outliers-in-categorical-data/<br>\n",
    "    pca collinearity removal/heatmap - https://towardsdatascience.com/how-do-you-apply-pca-to-logistic-regression-to-remove-multicollinearity-10b7f8e89f9b#:~:text=PCA%20in%20action%20to%20remove%20multicollinearity&text=PCA%20(Principal%20Component%20Analysis)%20takes,effectively%20eliminate%20multicollinearity%20between%20features.<br>\n",
    "    vif - https://towardsdatascience.com/how-to-remove-multicollinearity-using-python-4da8d9d8abb2<br>\n",
    "    pca 2D - https://towardsdatascience.com/principal-component-analysis-pca-from-scratch-in-python-7f3e2a540c51<br>\n",
    "    pca 3D - https://drzinph.com/pca-visualized-with-3d-scatter-plots/<br>\n",
    "    tsne -https://builtin.com/data-science/tsne-python<br>\n",
    "    umap - https://blog.ml.cmu.edu/2020/08/31/2-data-exploration/<br>\n",
    "    3D t-sne and umap -  https://plotly.com/python/t-sne-and-umap-projections/#project-data-into-3d-with-tsne-and-pxscatter3d<br>\n",
    "    knn - https://medium.datadriveninvestor.com/k-nearest-neighbors-in-python-hyperparameters-tuning-716734bc557f<br>\n",
    "    hyperparameter tuning - https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74<br>\n",
    "    model evaluation - https://medium.com/@MohammedS/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b<br>\n",
    "    pydot and graphviz - https://github.com/WillKoehrsen/Data-Analysis/blob/master/random_forest_explained/Random%20Forest%20Explained.ipynb<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn imports\n",
    "\n",
    "from sklearn import metrics, model_selection, ensemble\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "#data handling imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation imports\n",
    "# separated to reduce import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import umap.umap_ as umap\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preprocessing and Data Exploration__<br>\n",
    "We want to predict edibility<br>\n",
    "It can take values edible, poisonous or unknown. Unknown and poisonous are grouped together"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First read the file and format it as desired\n",
    "\n",
    "Missing values are stored as '?' characters so we convert to NaN to make the data easier to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to read raw data\n",
    "\n",
    "#read contents of data file\n",
    "file = pd.read_csv(\"agaricus-lepiota.data\", header = None)\n",
    "\n",
    "# create list to be used as headers\n",
    "features = ['edibility', 'capShape', 'capSurface', 'capColor', 'bruises', 'odor', \n",
    "            'gillAttachment', 'gillSpacing', 'gillSize', 'gillColor', \n",
    "            'stalkShape', 'stalkRoot', 'stalkSurfaceAboveRing', 'stalkSurfaceBelowRing', \n",
    "            'stalkColorAboveRing', 'stalkColorBelowRing', 'veilType', 'veilColor', \n",
    "            'ringNumber', 'ringType', 'sporePrintColor', 'population', 'habitat']\n",
    "\n",
    "#convert '?' to NaN\n",
    "file.replace({'?': np.nan}, inplace=True)\n",
    "\n",
    "#converting data frame to csv\n",
    "file.to_csv(\"Data/agaricus-lepiota.csv\", header=features, index=False)\n",
    "\n",
    "data = pd.read_csv(\"Data/agaricus-lepiota.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple data exploration for illustration<br>\n",
    "Shows that the only feature containing missing values is 'stalkRoot', with 2480 null values\n",
    "\n",
    "Created countplots to visualise some features attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head(5)) # print first 5 rows\n",
    "print(data.shape) # number of rows and columns\n",
    "print(data.info()) # data types of each feature\n",
    "print(data.isnull().sum()) # show how many NaN values in each feature\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# show even split of values in the feature to be predicted\n",
    "data['edibility'] = LabelEncoder().fit_transform(data['edibility'])\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "sns.countplot(x=data['edibility'])\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Edibility\")\n",
    "plt.title(\"Countplot to Show number of Edible (0) and Poisonous (1) data points\")\n",
    "fig.savefig(\"Images/Edibility Countplot.png\")\n",
    "\n",
    "# this visualisation works best for features with a wide range of possible values\n",
    "# chose 3 features as a starting point\n",
    "\n",
    "f = plt.figure(figsize=(15,5))\n",
    "f.add_subplot(1,3,1)\n",
    "sns.countplot(x = data['population'])\n",
    "sns.color_palette(\"pastel\")\n",
    "f.add_subplot(1,3,2)\n",
    "sns.countplot(x = data['ringNumber'])\n",
    "sns.color_palette(\"pastel\")\n",
    "f.add_subplot(1,3,3)\n",
    "sns.countplot(x=data['gillColor'])\n",
    "sns.color_palette(\"pastel\")\n",
    "plt.show()\n",
    "f.savefig(\"Images/3 Countplots.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data takes character values so we will need to use label encoding - OneHot encoding not applicable due to the high dimensionality of the dataset. OneHot Encoding would be much less memory efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for encoding the data\n",
    "\n",
    "#use label encoding on all features that are categorical\n",
    "le = LabelEncoder()\n",
    "\n",
    "for i in range(len(features)):\n",
    "   try:\n",
    "      data[features[i]] = le.fit_transform(data[features[i]])\n",
    "   except:\n",
    "      pass\n",
    "\n",
    "data.to_csv(\"Data/agaricus-lepiota-encoded.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using simple violin plots to show distibution of attributes within each feature. These demonstrated the need for outlier detection and elimination as there are features with vastly uneven attribute distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#violin plots to show distribution\n",
    "figure, axes = plt.subplots(3,7,figsize = (30,20))\n",
    "figure.suptitle(\"Violin Plots of feature scompared with Edibility\")\n",
    "\n",
    "graph_features = ['capShape', 'capSurface', 'capColor', 'bruises', 'odor', \n",
    "            'gillAttachment', 'gillSpacing', 'gillSize', 'gillColor', \n",
    "            'stalkShape', 'stalkRoot', 'stalkSurfaceAboveRing', 'stalkSurfaceBelowRing', \n",
    "            'stalkColorAboveRing', 'stalkColorBelowRing', 'veilColor', \n",
    "            'ringNumber', 'ringType', 'sporePrintColor', 'population', 'habitat']\n",
    "\n",
    "count = 0\n",
    "for i in range(0,3):\n",
    "    for j in range(0,7):\n",
    "        ax = sns.violinplot(ax = axes[i,j], data = data, x=\"edibility\", y = graph_features[count])\n",
    "        count +=1\n",
    "\n",
    "plt.savefig(\"Images/Violin Plots.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deletion methods of dealing with missing values<br>\n",
    "**Only use one of the 2 cells below at a time**\n",
    "\n",
    "**Don't use either if you're using the cell to predict missing values**\n",
    "\n",
    "1. Delete any column containing missing values\n",
    "2. Delete any row containing missing values\n",
    "\n",
    "Since only one feature contains missing values (stalkRoot) method 1 is most effective as it deletes less data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\n",
    "#removes column with missing values which in our data is only stalkRoot\n",
    "#one way to deal with missing values\n",
    "print(data.shape)\n",
    "\n",
    "treated_data = data.drop('stalkRoot', axis = 1).reset_index(drop=True)\n",
    "\n",
    "features.remove(\"stalkRoot\")\n",
    "print(features)\n",
    "\n",
    "# show how much data is lost\n",
    "print(treated_data.shape)\n",
    "\n",
    "#convert dataframe to csv\n",
    "treated_data.to_csv(\"Data/agaricus-lepiota-no-stalkRoot.csv\")\n",
    "\n",
    "#print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\n",
    "#removes all rows that have missing values\n",
    "print(data.shape)\n",
    "\n",
    "treated_data = data[data['stalkRoot'] != 4].reset_index(drop=True)\n",
    " \n",
    "# show how much data is lost\n",
    "print(treated_data.shape)\n",
    "\n",
    "#convert dataframe to csv\n",
    "treated_data.to_csv(\"Data/agaricus-lepiota-NaN-removed.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative way to deal with missing values: Use classifier based on values which aren't missing to predict the missing values<br>\n",
    "Need to be careful to avoid overfitting (as with any predictor)\n",
    "\n",
    "Could also set the values to some default or mean value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict missing values for stalkRoot\n",
    "\n",
    "#drop 'edibility' from dataframe as it will be the target feature in the later models\n",
    "#It would be a bad idea to use 'edibility' to predict missing 'stalkRoot' values then use those values to later predict 'edibility'\n",
    "NaN_predict = data.drop('edibility', axis = 1).reset_index(drop=True)\n",
    "\n",
    "#split into set that contains missing values for 'stalkRoot' and set that does not contan missing values for 'stalkRoot'\n",
    "#The 'NaN' values are encoded to be '4' so they are removed\n",
    "NaN_train_data = NaN_predict[NaN_predict['stalkRoot']!= 4].copy()\n",
    "NaN_test_data = NaN_predict[NaN_predict['stalkRoot'] == 4].copy()\n",
    "\n",
    "#split data missing values into train and test set\n",
    "NaN_X_train = NaN_train_data.drop('stalkRoot', axis = 1).reset_index(drop=True)\n",
    "NaN_y_train = NaN_train_data['stalkRoot']\n",
    "\n",
    "NaN_X_test = NaN_test_data.drop('stalkRoot', axis = 1).reset_index(drop=True)\n",
    "\n",
    "#create random forest class\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "#fit and predict data\n",
    "rfc.fit(NaN_X_train,NaN_y_train)\n",
    "y_pred = rfc.predict(NaN_X_test)\n",
    "\n",
    "#set NaN values to be the predicted values\n",
    "rounded_data = (np.rint(y_pred)).astype(int)\n",
    "NaN_test_data['stalkRoot'] = rounded_data\n",
    "\n",
    "NaN_test_data.to_csv(\"Data/predicted-missing-values.csv\")\n",
    "\n",
    "#combine the two dataframes to make the complete dataset\n",
    "frames = [NaN_train_data, NaN_test_data]\n",
    "treated_data = pd.concat(frames)\n",
    "treated_data = treated_data.sort_index()\n",
    "treated_data.insert(0, column = 'edibility', value = data['edibility'])\n",
    "\n",
    "treated_data.to_csv(\"Data/full-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = treated_data.drop('edibility', axis = 1).reset_index(drop=True)\n",
    "y = treated_data['edibility'] \n",
    "\n",
    "graph_labels = []\n",
    "for i in y:\n",
    "    if i == 0:\n",
    "        graph_labels.append(\"Edible\")\n",
    "    else:\n",
    "        graph_labels.append(\"Poisonous\")\n",
    "\n",
    "#scale the data for correct visualisation\n",
    "data_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Visualisation__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PCA<br>\n",
    "Linear method so less complex than others such as T-SNE and UMAP, meaning it takes much less time<br>\n",
    "But not so useful to visualise our dataset as shown by the explained variance and scree plot<br>\n",
    "\n",
    "However we could be possibly use PCA to reduce multicollinearity but there are other methods to also consider<br>\n",
    "For example using the first 8 PC's greatly reduces the dimesionality of out dataset while mostly maintaining important information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualisation pca 2D\n",
    "pca = PCA(random_state=42)\n",
    "pca_features = pca.fit_transform(data_scaled)\n",
    "\n",
    "#calculate percieved variance\n",
    "per_var = np.round(pca.explained_variance_ratio_*100, decimals = 1)\n",
    "print(per_var)\n",
    "labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "\n",
    "#to be seen on a 2D-plot we can only use PC1 and PC2 which gives us the highest explained variance but still very low\n",
    "#around 19% + 12% = 31% explained variance which is bad\n",
    "plt.bar(x= range(1,len(per_var)+1), height = per_var, tick_label = labels)\n",
    "plt.title('Scree Plot to Show the Explained Variance of Each PC')\n",
    "plt.xlabel(\"PCA NO.\")\n",
    "plt.ylabel(\"Explained Variance (%)\")\n",
    "plt.savefig(\"Images/PCA/PCA_distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = plt.rcParamsDefault[\"figure.figsize\"]\n",
    "\n",
    "pca_df = pd.DataFrame({'pca_1': pca_features[:,0], 'pca_2': pca_features[:,1], 'Edibility': graph_labels})\n",
    "print(pca_df)\n",
    "\n",
    "#plot pca 1 and pca 2\n",
    "sns.scatterplot(x = 'pca_1', y = 'pca_2', hue = 'Edibility', data = pca_df)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title(\"2D Visualisation using PCA\")\n",
    "plt.savefig(\"Images/PCA/2D PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA 3D\n",
    "pca = PCA(n_components = 3, random_state=42)\n",
    "pca_features = pca.fit_transform(data_scaled)\n",
    "\n",
    "#calculate percieved variance\n",
    "per_var = np.round(pca.explained_variance_ratio_*100, decimals = 1)\n",
    "print(per_var)\n",
    "print(pca_features)\n",
    "\n",
    "treated_data[\"edibility\"] = treated_data[\"edibility\"].astype(str)\n",
    "\n",
    "#plot PCA 3D\n",
    "pca_fig = px.scatter_3d(\n",
    "    pca_features, x=0, y=1, z=2,\n",
    "    color=graph_labels, labels={'color': 'Edibility'},\n",
    "    title = \"Dimensionality reduction using PCA to visualise the dataset\"\n",
    ")\n",
    "pca_fig.update_traces(marker_size=8)\n",
    "\n",
    "pca_fig.update_layout(scene = dict(\n",
    "                    xaxis_title='PCA 1',\n",
    "                    yaxis_title='PCA 2',\n",
    "                    zaxis_title='PCA 3')\n",
    ")\n",
    "\n",
    "#save as html to view the 3D graph interactively\n",
    "pca_fig.write_html(\"Images/PCA/PCA-3D.html\")\n",
    "\n",
    "pca_fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. T-SNE<br>\n",
    "Unlike pca, it's not linear so much more complex<br>\n",
    "The result of t-SNE is greatly affected by the 'perplexity' hyperparameter<br>\n",
    "Try perplexity values in the range 5-100 default is 30. Higher perplexity takes longer but may be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualisation t-sne 2D\n",
    "n_components = 2\n",
    "tsne = TSNE(n_components, perplexity=50, random_state = 42)\n",
    "tsne_features = tsne.fit_transform(data_scaled)\n",
    "\n",
    "#create data-frame used to plot\n",
    "tsne_df = pd.DataFrame({'tsne_1': tsne_features[:,0], 'tsne_2': tsne_features[:,1], 'label': treated_data['edibility']})\n",
    "\n",
    "#plot tnse 1 and tsne 2\n",
    "sns.scatterplot(x = 'tsne_1', y = 'tsne_2', hue = 'label', data = tsne_df)\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.title(\"2D Visualisation using t-SNE\")\n",
    "plt.savefig(\"Images/t-SNE/2D t-SNE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D t-SNE using plotly\n",
    "n_components = 3\n",
    "\n",
    "#create t-SNE class and set hyperparameters\n",
    "tsne = TSNE(n_components, perplexity=50, random_state=42)\n",
    "tsne_features = tsne.fit_transform(data_scaled)\n",
    "\n",
    "treated_data[\"edibility\"] = treated_data[\"edibility\"].astype(str)\n",
    "\n",
    "#plot t-SNE\n",
    "tsne_fig = px.scatter_3d(\n",
    "    tsne_features, x=0, y=1, z=2,\n",
    "    color=graph_labels, labels={'color': 'Edibility'},\n",
    "    title = \"Dimensionality reduction using t-SNE to visualise the dataset\"\n",
    ")\n",
    "tsne_fig.update_traces(marker_size=8)\n",
    "\n",
    "tsne_fig.update_layout(scene = dict(\n",
    "                    xaxis_title='t-SNE 1',\n",
    "                    yaxis_title='t-SNE 2',\n",
    "                    zaxis_title='t-SNE 3')\n",
    ")\n",
    "\n",
    "#save graph as html to be viewed interactively\n",
    "tsne_fig.write_html(\"Images/t-SNE/t-SNE-3D.html\")\n",
    "\n",
    "tsne_fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. UMAP <br>\n",
    "UMAP works very similarly to t-SNE but gets more efficient for higher volumes of data <br>\n",
    "Result greatly affected by n_neighbors and min_dist hyperparameters <br>\n",
    "For n_neighbors try range 5-100 and min_dist 0.1-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualisation UMAP\n",
    "\n",
    "#create UMAP class and set hyperparameters\n",
    "fit = umap.UMAP(\n",
    "    n_neighbors=50,\n",
    "    min_dist=0.25,\n",
    "    n_components=2,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "umap_features = fit.fit_transform(data_scaled)\n",
    "\n",
    "#create datafram to plot UMAP\n",
    "umap_df = pd.DataFrame({'umap_1': umap_features[:,0], 'umap_2': umap_features[:,1], 'Edibility': graph_labels})\n",
    "\n",
    "\n",
    "#plot 2D UMAP\n",
    "sns.scatterplot(x = 'umap_1', y = 'umap_2', hue = 'Edibility', data = umap_df)\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.title(\"2D Visualisation using UMAP\")\n",
    "plt.savefig(\"Images/UMAP/2D UMAP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UMAP 3D using plotly\n",
    "\n",
    "#create UMAP class and set hyperparameters\n",
    "fit = umap.UMAP(\n",
    "    n_neighbors=50,\n",
    "    min_dist=0.75,\n",
    "    n_components=3,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "umap_features = fit.fit_transform(data_scaled)\n",
    "\n",
    "treated_data[\"edibility\"] = treated_data[\"edibility\"].astype(str)\n",
    "\n",
    "#plot UMAP 3D\n",
    "umap_fig = px.scatter_3d(\n",
    "    umap_features, x=0, y=1, z=2,\n",
    "    color=graph_labels, labels={'color': 'Edibility'},\n",
    "    title = \"Dimensionality reduction using UMAP to visualise the dataset\"\n",
    ")\n",
    "umap_fig.update_traces(marker_size=5)\n",
    "\n",
    "umap_fig.update_layout(scene = dict(\n",
    "                    xaxis_title='UMAP 1',\n",
    "                    yaxis_title='UMAP 2',\n",
    "                    zaxis_title='UMAP 3')\n",
    ")\n",
    "\n",
    "#save graph as html to be viewed interactively\n",
    "umap_fig.write_html(\"Images/UMAP/UMAP-3D.html\")\n",
    "umap_fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now deal with outliers<br>\n",
    "We define outliers as values a category can take which is significantly more or less frequent than the others<br>\n",
    "\n",
    "Detect outliers based on relative frequency and remove any rows containing outliers in at least one category<br>\n",
    "Then show histogram of data distribution within categories containing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to detect and remove outliers\n",
    "\n",
    "#decides relative frequency threshold, below which values are considered outliers\n",
    "threshold = 0.01\n",
    "contains_outliers = []\n",
    "outlier_features = []\n",
    "num_values = data.nunique()\n",
    "\n",
    "print(\"Original dataset:\",treated_data.shape)\n",
    "\n",
    "#loop through categories and identify which contain outliers according to the above definitions\n",
    "for i in range(len(features)):\n",
    "    if num_values[i] > 2:\n",
    "        value_frequencies = treated_data[features[i]].value_counts(normalize=True) #normalize parameter converts values to relative frequency\n",
    "\n",
    "        #loop through features that contain outliers and remove the all rows that contain the outlier values\n",
    "        for j in range(len(value_frequencies)):\n",
    "            if value_frequencies.iloc[j] < threshold:\n",
    "                treated_data = treated_data[treated_data[features[i]] != value_frequencies.index[j]]\n",
    "                contains_outliers.append(value_frequencies)\n",
    "                outlier_features.append(features[i])\n",
    "\n",
    "print(\"Outliers removed:\",treated_data.shape)\n",
    "\n",
    "#now display histogram\n",
    "sns.set_theme(style = None)\n",
    "\n",
    "if len(contains_outliers) != 0:\n",
    "    for x in range(len(contains_outliers)):\n",
    "        outlier_histogram = plt.hist(contains_outliers[x], alpha = 0.5, label = outlier_features[x])\n",
    "\n",
    "    plt.legend(loc='upper right',prop={'size': 6})\n",
    "    plt.xlabel(\"Relative frequency\")\n",
    "    plt.ylabel(\"Encoded label\")\n",
    "    plt.title(\"Histograms showing the relative frequency of attributes within each feature\")\n",
    "    plt.savefig(\"Images/Frequency Histogram.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check for any features which only contain one value<br>\n",
    "These won't affect the model performance as the entire feature is constant so we can remove them to simplify the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to remove redundant features\n",
    "\n",
    "num_values = treated_data.nunique()\n",
    "removed_features = []\n",
    "\n",
    "#loop that finds features that have only one attribute value\n",
    "j = 0\n",
    "for i in range(len(features)):\n",
    "    if num_values[i] == 1:\n",
    "        treated_data = treated_data.drop(features[j],axis=1).reset_index(drop=True)\n",
    "        removed_features.append(features[j])\n",
    "        features.remove(features[j])\n",
    "    else:\n",
    "        j += 1\n",
    "\n",
    "#remove features\n",
    "X = treated_data.drop('edibility', axis = 1).reset_index(drop=True) #update treated X\n",
    "y = treated_data['edibility'] #update treated y\n",
    "\n",
    "print(\"Removed\",removed_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display heatmap to explore correlation between features<br>\n",
    "Multicollinearity can lead to overfitting so need to remove correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell that uses variance inflation factor to identify and remove highly correlated data\n",
    "\n",
    "#create a heatmap showing feature correlation\n",
    "fig = plt.figure(figsize=(17, 13))\n",
    "sns.set(font_scale = 0.8)\n",
    "sns.heatmap(X.corr(), annot=True, annot_kws={\"size\": 12})\n",
    "plt.savefig(\"Images/Heatmap.png\")\n",
    "\n",
    "#as you can see from heatmap there are some features with high correlation\n",
    "\n",
    "#create dataframe with all features and their VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X.columns\n",
    "\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "\t\t\t\t\t\tfor i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data)\n",
    "\n",
    "features_to_drop = []\n",
    "\n",
    "#loop through the features and add those with VIF higher than 5 to a list\n",
    "for i in range(len(X.columns)):\n",
    "\tif vif_data[\"VIF\"][i] > 5:\n",
    "\t\tdrop = vif_data[\"VIF\"][i]\n",
    "\t\tfeatures_to_drop.append(vif_data[\"feature\"][i])\n",
    "\n",
    "#create new dataframe identified features removed\n",
    "uncorrelated_X = X.drop(features_to_drop, axis = 1).reset_index(drop=True)\n",
    "\n",
    "#scale for visualisation\n",
    "uncorrelated_X_scaled = StandardScaler().fit_transform(uncorrelated_X)\n",
    "\n",
    "cleaned_features = uncorrelated_X.columns\n",
    "\n",
    "#generally features with VIF > 5 get removed but we can experiment with slightly higher i.e > 6\n",
    "\n",
    "#create heatmap to compare feature correlation of new dataframe\n",
    "fig2 = plt.figure(figsize=(15, 10))\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.heatmap(uncorrelated_X.corr(), annot=True, annot_kws={\"size\": 60},)\n",
    "plt.savefig(\"Images/Heatmap 2.png\")\n",
    "plt.show()\n",
    "#as seen by second heatmap these have much less colinearality\n",
    "\n",
    "sns.set(font_scale = 1.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__All the data exploration, preprocessing and Visualisation is now complete__<br>\n",
    "The following cells contain code for hyperparamter exploration, model comparison and model evaluation for 3 models: K-Nearest Neighbours(KNN), Random Forest Classifier(RFC) and Support Vector Classifier(SVC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Models__ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. K-nearest neighbours<br>\n",
    "Exploration of accuarcy and time against Knn hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn hyperparameter exploration: accuracy v and time vs n_neighbors\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2, random_state=42)\n",
    "n_neighbours = range(1,30)\n",
    "\n",
    "#create lists to append times and accuracies to\n",
    "accuracies = []\n",
    "times = []\n",
    "\n",
    "#measure the accuracy and time taken of knn modle for each value of n_neighbours\n",
    "for i in range(len(n_neighbours)):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbours[i])\n",
    "    start_time = time.time()\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "#plot both graphs side by side to be compared\n",
    "figure, axes = plt.subplots(1,2,figsize = (12,6))\n",
    "figure.suptitle(\"Accuracy and Time Plots against n_neighbours\")\n",
    "\n",
    "ax = sns.lineplot(x = n_neighbours, y = accuracies, ax = axes[0])\n",
    "ax.set(xlabel='n_neighbours', ylabel='Accuracy')\n",
    "ax2 = sns.lineplot(x = n_neighbours, y = times, ax = axes[1])\n",
    "ax2.set(xlabel='n_neighbours', ylabel='Time (s)')\n",
    "plt.savefig(\"Images/KNN/KNN accuracy and time vs n_neighbours.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn hyperparameter exploration: accuracy v and time vs leaf size\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2, random_state=42)\n",
    "leaf_sizes = range(1,50)\n",
    "\n",
    "#create lists to append times and accuracies to\n",
    "accuracies = []\n",
    "times = []\n",
    "\n",
    "#measure the accuracy and time taken of knn modle for each value of leaf_size\n",
    "for i in range(len(leaf_sizes)):\n",
    "    knn = KNeighborsClassifier(leaf_size=leaf_sizes[i],algorithm = 'kd_tree')\n",
    "    start_time = time.time()\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "#plot both graphs side by side to be compared\n",
    "figure, axes = plt.subplots(1,2,figsize = (12,6))\n",
    "figure.suptitle(\"Accuracy and Time Plots against leaf_size\")\n",
    "\n",
    "ax = sns.lineplot(x = leaf_sizes, y = accuracies, ax = axes[0])\n",
    "ax.set(xlabel='leaf_size', ylabel='Accuracy')\n",
    "ax2 = sns.lineplot(x = leaf_sizes , y = times, ax = axes[1])\n",
    "ax2.set(xlabel='leaf_size', ylabel='Time (s)')\n",
    "plt.savefig(\"Images/KNN/KNN accuracy and time vs leaf_size.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decsion Regions exploration n_neighbours and leaf_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn hyperparameter exploration: n_neighbours decision regions\n",
    "\n",
    "#create range of n_neighbours to explore\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2, random_state=42)\n",
    "n_neighbours = [1, 2, 5, 10, 12, 15, 25] # points on the accuracy graph with changes\n",
    "\n",
    "#for each candidate value plot a decision region graph\n",
    "for i in range(len(n_neighbours)):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbours[i])\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    for j in range(2):\n",
    "        plt.subplot(2,1,j+1)\n",
    "        plot_decision_regions(X_test.values, y_test.values, clf = knn, legend = 2, feature_index = [0,2], filler_feature_values={1: j}, filler_feature_ranges={1:0.75})\n",
    "        plt.title(\"n_neighbors=\"+str(n_neighbours[i])+\" gillSpacing=\"+str(j))\n",
    "        plt.xlabel(\"capSurface\")\n",
    "        plt.ylabel(\"habitat\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Images/KNN/KNN Regions/n_neighbours = \"+str(n_neighbours[i])+\".png\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn hyperparameter exploration: leaf_size decision regions\n",
    "\n",
    "#create range of n_neighbours to explore\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2, random_state=42)\n",
    "leaf_sizes = [10, 30,50] # points on the accuracy graph with changes\n",
    "\n",
    "#for each candidate value plot a decision region graph\n",
    "for i in range(len(leaf_sizes)):\n",
    "    knn = KNeighborsClassifier(leaf_size=leaf_sizes[i])\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    for j in range(2):\n",
    "        plt.subplot(2,1,j+1)\n",
    "        plot_decision_regions(X_test.values, y_test.values, clf = knn, legend = 2, feature_index = [0,2], filler_feature_values={1: j}, filler_feature_ranges={1:0.75})\n",
    "        plt.title(\"leaf_size =\"+str(leaf_sizes[i])+\" gillSpacing=\"+str(j))\n",
    "        plt.xlabel(\"capSurface\")\n",
    "        plt.ylabel(\"habitat\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"Images/KNN/KNN Regions/leaf_size = \"+str(leaf_sizes[i])+\".png\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make informed decisions about hyperparameter candidate value ranges for k-fold cross validation of the Knn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for  knn model\n",
    "\n",
    "# hyperparameters\n",
    "n_neighbors = list(range(1,30))\n",
    "weights = ['uniform','distance']\n",
    "leaf_size = list(range(1,50))\n",
    "p = [1,2]\n",
    "\n",
    "# create dictionary\n",
    "random_grid = {'n_neighbors': n_neighbors,\n",
    "               'weights': weights,\n",
    "               'algorithm': ['kd_tree'],\n",
    "               'leaf_size': leaf_size,\n",
    "               'p': p}\n",
    "\n",
    "# baseline model\n",
    "knn_baseline = KNeighborsClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2)\n",
    "knn_baseline.fit(X_train, y_train)\n",
    "baseline_knn_pred = knn_baseline.predict(X_test)\n",
    "\n",
    "# random hyperparameter values\n",
    "knn_random = RandomizedSearchCV(estimator = knn_baseline, param_distributions = random_grid, n_iter = 200, cv = 3, verbose=2, random_state=42, n_jobs = -1, scoring = 'accuracy')\n",
    "\n",
    "knn_random.fit(X_train, y_train)\n",
    "\n",
    "best_random_values = knn_random.best_params_\n",
    "print(\"\\n\", best_random_values, \"\\n\")\n",
    "best_random_knn = knn_random.best_estimator_\n",
    "print(best_random_knn)\n",
    "\n",
    "#predict using best random model and get model accuracy report\n",
    "best_random_pred = best_random_knn.predict(X_test)\n",
    "\n",
    "#create a refined hyperparameter grid with values close to the best random estimator to look for further optimization\n",
    "# fits may fail if n_neighbors or leaf_size < 15 however they will just be skipped so this is okay\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range((best_random_values['n_neighbors']-10),(best_random_values['n_neighbors']+10))),\n",
    "    'weights': [best_random_values['weights']],\n",
    "    'algorithm': ['kd_tree'],\n",
    "    'leaf_size': list(range((best_random_values['leaf_size']-15),(best_random_values['leaf_size']+15))),\n",
    "    'p': [best_random_values['p']]\n",
    "}\n",
    "\n",
    "knn_refined = KNeighborsClassifier()\n",
    "\n",
    "# find the best scoring model using the refined hyperparameter grid\n",
    "knn_grid = GridSearchCV(estimator = knn_refined, param_grid = param_grid, cv = 3, verbose=2, n_jobs = -1, scoring = 'accuracy')\n",
    "\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\", knn_grid.best_params_, \"\\n\")\n",
    "best_grid_knn = knn_grid.best_estimator_\n",
    "print(best_grid_knn)\n",
    "\n",
    "# predict with refined model\n",
    "best_refined_pred = best_grid_knn.predict(X_test)\n",
    "\n",
    "#create figure to plot 3 confusion matrix on of each model iteration\n",
    "figure, axes = plt.subplots(1,3,figsize = (15,5))\n",
    "figure.suptitle(\"Confusion matrices of each model iteration\")\n",
    "\n",
    "#create confusion matrix and labels for clear plotting\n",
    "cf_matrix = confusion_matrix(y_test, baseline_knn_pred)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "#show model accuracy report\n",
    "print(\"Baseline\\n\")\n",
    "print(classification_report(y_test,baseline_knn_pred))\n",
    "\n",
    "print(cf_matrix)\n",
    "\n",
    "#plot confusion matrix\n",
    "ax = sns.heatmap(cf_matrix, annot = labels,fmt = '', cmap = 'Blues', ax = axes[0], cbar = False)\n",
    "\n",
    "#show model accuracy report\n",
    "print(\"Random Search\\n\")\n",
    "print(classification_report(y_test,best_random_pred))\n",
    "\n",
    "#create second confusion matrix and labels for clear plotting\n",
    "cf_matrix_2 = confusion_matrix(y_test, best_random_pred)\n",
    "\n",
    "print(cf_matrix_2)\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix_2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix_2.flatten()/np.sum(cf_matrix_2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "#plot second matrix\n",
    "ax = sns.heatmap(cf_matrix_2, annot = labels,fmt = '', cmap = 'Blues', ax = axes[1],cbar = False)\n",
    "\n",
    "print(\"Grid Search\\n\")\n",
    "print(classification_report(y_test,best_refined_pred))\n",
    "\n",
    "#create third confusion matrix and labels for clear plotting\n",
    "cf_matrix_3 = confusion_matrix(y_test, best_refined_pred)\n",
    "\n",
    "print(cf_matrix_3)\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix_3.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix_3.flatten()/np.sum(cf_matrix_3)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "#plot third confusion matrix and save figure as png\n",
    "ax = sns.heatmap(cf_matrix_3, annot = labels,fmt = '', cmap = 'Blues', ax = axes[2])\n",
    "\n",
    "plt.savefig(\"Images/KNN/Confusion Matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Random Forest Classifier(RFC)__<br>\n",
    "Exploration of accuarcy and time against RFC hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC hyperparameter exploration: accuracy and time vs n_estimators\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2, random_state=42)\n",
    "n_estimators = range(1,100)\n",
    "\n",
    "#create lists to store times and accuracies\n",
    "times = []\n",
    "accuracies = []\n",
    "\n",
    "#for each candidate value calculate the time taken and accuracy of the RFC model\n",
    "for i in range(len(n_estimators)):\n",
    "    start_time = time.time()\n",
    "    rfc = RandomForestClassifier(n_estimators=n_estimators[i])\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "#plot these graphs on a figure for clear comparision\n",
    "figure, axes = plt.subplots(1,2,figsize = (12,6))\n",
    "figure.suptitle(\"Accuracy and Time Plots against n_estimators\")\n",
    "\n",
    "ax = sns.lineplot(x = n_estimators, y = accuracies, ax = axes[0])\n",
    "ax.set(xlabel='n_esimators', ylabel='Accuracy')\n",
    "ax2 = sns.lineplot(x = n_estimators, y = times, ax = axes[1])\n",
    "ax2.set(xlabel='n_estimators', ylabel='Time (s)')\n",
    "plt.savefig(\"Images/RFC/RFC accuracy and time vs n_estimators.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC hyperparameter exploration: accuracy and time vs max_depth\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2, random_state=42)\n",
    "max_depths = range(1,30)\n",
    "\n",
    "#create lists to store times and accuracies\n",
    "times = []\n",
    "accuracies = []\n",
    "\n",
    "#for each candidate value calculate the time taken and accuracy of the RFC model\n",
    "for i in range(len(max_depths)):\n",
    "    start_time = time.time()\n",
    "    rfc = RandomForestClassifier(max_depth=max_depths[i])\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "#plot these graphs on a figure for clear comparision\n",
    "figure, axes = plt.subplots(1,2,figsize = (12,6))\n",
    "figure.suptitle(\"Accuracy and Time Plots against max_depth\")\n",
    "\n",
    "ax = sns.lineplot(x = max_depths, y = accuracies, ax = axes[0])\n",
    "ax.set(xlabel='max_depth', ylabel='Accuracy')\n",
    "ax2 = sns.lineplot(x = max_depths, y = times, ax = axes[1])\n",
    "ax2.set(xlabel='max_depth', ylabel='Time (s)')\n",
    "plt.savefig(\"Images/RFC/RFC accuracy and time vs max_depth.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC hyperparameter exploration: accuracy and time vs min_samples_leaf\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2, random_state=42)\n",
    "min_samples_leaves = range(1,50)\n",
    "\n",
    "#create lists to store times and accuracies\n",
    "times = []\n",
    "accuracies = []\n",
    "\n",
    "#for each candidate value calculate the time taken and accuracy of the RFC model\n",
    "for i in range(len(min_samples_leaves)):\n",
    "    start_time = time.time()\n",
    "    rfc = RandomForestClassifier(min_samples_leaf=min_samples_leaves[i])\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "#plot these graphs on a figure for clear comparision\n",
    "figure, axes = plt.subplots(1,2,figsize = (12,6))\n",
    "figure.suptitle(\"Accuracy and Time Plots against min_samples_leaf\")\n",
    "\n",
    "ax = sns.lineplot(x = min_samples_leaves, y = accuracies, ax = axes[0])\n",
    "ax.set(xlabel='min_samples_leaf', ylabel='Accuracy')\n",
    "ax2 = sns.lineplot(x = min_samples_leaves, y = times, ax = axes[1])\n",
    "ax2.set(xlabel='min_samples_leaf', ylabel='Time (s)')\n",
    "plt.savefig(\"Images/RFC/RFC accuracy and time vs min_samples_leaf.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision region exploration of RFC hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC n_estimators hyperparameter exploration\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2)\n",
    "\n",
    "#create list of n_estimators and fit a model for each\n",
    "n_estimators = [1,2,5,10,20,50,100]\n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    rfc_n_estimator = RandomForestClassifier(n_estimators= n_estimator, random_state = 42)\n",
    "    rfc_n_estimator.fit(X_train,y_train)\n",
    "\n",
    "    #create a decision region plot for each value of n_estimators\n",
    "    for i in range(2):\n",
    "        plt.subplot(2,1,i+1)\n",
    "        plot_decision_regions(X_test.values, y_test.values, clf = rfc_n_estimator, legend = 2, feature_index = [0,2], filler_feature_values={1: i}, filler_feature_ranges={1:0.75})\n",
    "        title = \"n_estimators = \" + str(n_estimator) + \" gillSpacing=\"+str(i)\n",
    "        print(title)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"capSurface\")\n",
    "        plt.ylabel(\"habitat\")\n",
    "\n",
    "    #save plot as png\n",
    "    image_directory = \"Images/RFC/RFC Regions/n_estimators = \" + str(n_estimator) + \".png\"\n",
    "    print(image_directory)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_directory)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC max_depth hyperparameter exploration\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2)\n",
    "\n",
    "#create list of max_depth candidate values and fit an RFC model for each\n",
    "max_depths = [1,2,5,10,20,30]\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    rfc_max_depth = RandomForestClassifier(max_depth= max_depth, random_state = 42)\n",
    "    rfc_max_depth.fit(X_train,y_train)\n",
    "\n",
    "    #plot a decision region graph for each candidate value\n",
    "    for i in range(2):\n",
    "        plt.subplot(2,1,i+1)\n",
    "        plot_decision_regions(X_test.values, y_test.values, clf = rfc_max_depth, legend = 2, feature_index = [0,2], filler_feature_values={1: i}, filler_feature_ranges={1:0.75})\n",
    "        title = \"max_depth = \" + str(max_depth) + \" gillSpacing=\"+str(i)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"capSurface\")\n",
    "        plt.ylabel(\"habitat\")\n",
    "\n",
    "    #save plots as png\n",
    "    image_directory = \"Images/RFC/RFC Regions/max_depth = \" + str(max_depth) + \".png\"\n",
    "    print(image_directory)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_directory)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC min_samples_leaf hyperparameter exploration\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2)\n",
    "\n",
    "#create list for range of candidate values and fit an RFC model\n",
    "min_samples_leaves = [2,5,10,20,50]\n",
    "\n",
    "for min_samples_leaf in min_samples_leaves:\n",
    "    rfc_min_samples_leaf = RandomForestClassifier(min_samples_leaf= min_samples_leaf, random_state = 42)\n",
    "    rfc_min_samples_leaf.fit(X_train,y_train)\n",
    "\n",
    "    #plot decision region graph for each candidate value\n",
    "    for i in range(2):\n",
    "        plt.subplot(2,1,i+1)\n",
    "        plot_decision_regions(X_test.values, y_test.values, clf = rfc_min_samples_leaf, legend = 2, feature_index = [0,2], filler_feature_values={1: i}, filler_feature_ranges={1:0.75})\n",
    "        title = \"min_samples_leaf = \" + str(min_samples_leaf) + \" gillSpacing=\"+str(i)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"capSurface\")\n",
    "        plt.ylabel(\"habitat\")\n",
    "\n",
    "    #save plots as png\n",
    "    image_directory = \"Images/RFC/RFC Regions/min_samples_leaf = \" + str(min_samples_leaf) + \".png\"\n",
    "    print(image_directory)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_directory)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make informed decisions about hyperparameter candidate value ranges for k-fold cross validation of the RFC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for RandomForestClassifier\n",
    "\n",
    "#create distribution of chosen hyperparamaters to be used in random search\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 10)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_leaf = [2, 4, 6]\n",
    "\n",
    "#create dictionary with distribution of chosen hyperparameters\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "#basline model to compare to when optimising\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2)\n",
    "\n",
    "baseline_rfc = RandomForestClassifier(random_state = 42, n_estimators = 10)\n",
    "\n",
    "baseline_rfc.fit(X_train, y_train)\n",
    "baseline_rfc_pred = baseline_rfc.predict(X_test)\n",
    "\n",
    "#find best scoring random hyperparameter combination\n",
    "rfc_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1, scoring = 'accuracy')\n",
    "\n",
    "rfc_random.fit(X_train, y_train)\n",
    "best_random_values = rfc_random.best_params_\n",
    "\n",
    "print(\"\\n\", rfc_random.best_params_, \"\\n\")\n",
    "best_random_rfc = rfc_random.best_estimator_\n",
    "print(best_random_rfc)\n",
    "\n",
    "#predict using best random model and get model accuracy report\n",
    "best_pred = best_random_rfc.predict(X_test)\n",
    "\n",
    "#create a refined hyperparameter grid with values close to the best random estimator to look for further optimization\n",
    "param_grid = {\n",
    "    'n_estimators': list(range((best_random_values['n_estimators']-20),(best_random_values['n_estimators']+20))),\n",
    "    'max_depth': list(range((best_random_values['max_depth']-9),(best_random_values['max_depth']+10))),\n",
    "    'min_samples_leaf': list(range((best_random_values['min_samples_leaf']-1),(best_random_values['min_samples_leaf']+1)))\n",
    "}\n",
    "\n",
    "rf2 = RandomForestClassifier()\n",
    "\n",
    "#find the best scoring model using the refined hyperparameter grid\n",
    "rfc_grid = GridSearchCV(estimator = rf2, param_grid = param_grid, cv = 3, verbose=2, n_jobs = -1, scoring = 'accuracy')\n",
    "\n",
    "rfc_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\", rfc_grid.best_params_, \"\\n\")\n",
    "best_grid_rf = rfc_grid.best_estimator_\n",
    "print(best_grid_rf)\n",
    "\n",
    "#predict values using this model and show accuracy to compare models later\n",
    "best_pred2 = best_grid_rf.predict(X_test)\n",
    "\n",
    "#create figure to plot 3 confusion matrix on of each model iteration\n",
    "figure, axes = plt.subplots(1,3,figsize = (15,5))\n",
    "figure.suptitle(\"Confusion matrices of each model iteration\")\n",
    "\n",
    "#create confusion matrix and labels for clear plotting\n",
    "cf_matrix = confusion_matrix(y_test, baseline_rfc_pred)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "#show model accuracy report\n",
    "print(\"Baseline\\n\")\n",
    "print(classification_report(y_test,baseline_rfc_pred))\n",
    "\n",
    "print(cf_matrix)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot = labels,fmt = '', cmap = 'Blues', ax = axes[0], cbar = False)\n",
    "\n",
    "print(\"Random Search\\n\")\n",
    "print(classification_report(y_test,best_pred))\n",
    "\n",
    "#create second confusion matrix and labels for clear plotting\n",
    "cf_matrix_2 = confusion_matrix(y_test, best_pred)\n",
    "\n",
    "print(cf_matrix_2)\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix_2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix_2.flatten()/np.sum(cf_matrix_2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix_2, annot = labels,fmt = '', cmap = 'Blues', ax = axes[1],cbar = False)\n",
    "\n",
    "print(\"Grid Search\\n\")\n",
    "print(classification_report(y_test,best_pred2))\n",
    "\n",
    "#create third confusion matrix and labels for clear plotting\n",
    "cf_matrix_3 = confusion_matrix(y_test, best_pred2)\n",
    "\n",
    "print(cf_matrix_3)\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix_3.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix_3.flatten()/np.sum(cf_matrix_3)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix_3, annot = labels,fmt = '', cmap = 'Blues', ax = axes[2])\n",
    "plt.savefig(\"Images/RFC/Confusion Matrix.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fast_rfc = RandomForestClassifier(n_estimators = 200, min_samples_leaf= 4, max_depth = 20, random_state = 42)\n",
    "\n",
    "fast_rfc.fit(X_train,y_train)\n",
    "fast_predict = fast_rfc.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, fast_predict))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.Support Vector Classifier(SVC)__<br>\n",
    "Explore the time taken and accuracy for a range of  SVC hyperparameter candidate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparameter exploration: accuracy and time vs C\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2, random_state=42)\n",
    "c = range(1,30)\n",
    "\n",
    "#create lists for accuracies and times\n",
    "accuracies = []\n",
    "times = []\n",
    "\n",
    "#calculate the accuray and time taken of the SVC model for each candidate value\n",
    "for i in range(len(c)):\n",
    "    svc = SVC(C=c[i])\n",
    "    start_time = time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "#plot both on a figure for clear comparision\n",
    "figure, axes = plt.subplots(1,2,figsize = (12,6))\n",
    "figure.suptitle(\"Accuracy and Time Plots against C\")\n",
    "\n",
    "ax = sns.lineplot(x = c, y = accuracies, ax = axes[0])\n",
    "ax.set(xlabel='C', ylabel='Accuracy')\n",
    "ax2 = sns.lineplot(x = c, y = times, ax = axes[1])\n",
    "ax2.set(xlabel='C', ylabel='Time (s)')\n",
    "plt.savefig(\"Images/SVC/SVC accuracy and time vs C.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC hyperparameter exploration: accuracy and time vs gamma\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2, random_state=42)\n",
    "gamma = range(1,50)\n",
    "\n",
    "#create lists for accuracies and times\n",
    "times = []\n",
    "accuracies = []\n",
    "\n",
    "#calculate the accuray and time taken of the SVC model for each candidate value\n",
    "for i in range(len(gamma)):\n",
    "    start_time = time.time()\n",
    "    svc = SVC(gamma= gamma[i])\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    times.append(end_time - start_time)\n",
    "\n",
    "#plot both on a figure for clear comparision\n",
    "figure, axes = plt.subplots(1,2,figsize = (12,6))\n",
    "figure.suptitle(\"Accuracy and Time Plots against Gamma\")\n",
    "\n",
    "ax = sns.lineplot(x = gamma, y = accuracies, ax = axes[0])\n",
    "ax.set(xlabel='Gamma', ylabel='Accuracy')\n",
    "ax2 = sns.lineplot(x = gamma, y = times, ax = axes[1])\n",
    "ax2.set(xlabel='Gamma', ylabel='Time (s)')\n",
    "plt.savefig(\"Images/SVC/SVC accuracy and time vs gamma.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision regions exploration for SVC hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC gamma hyperparameter exploration\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2)\n",
    "\n",
    "gammas = [0.1,1,10,50]\n",
    "\n",
    "for gamma in gammas:\n",
    "    svc_gamma = SVC(gamma = gamma, random_state = 42)\n",
    "    svc_gamma.fit(X_train,y_train)\n",
    "\n",
    "    for i in range(2):\n",
    "        plt.subplot(2,1,i+1)\n",
    "        plot_decision_regions(X_test.values, y_test.values, clf = svc_gamma, legend = 2, feature_index = [0,2], filler_feature_values={1: i}, filler_feature_ranges={1:0.75})\n",
    "        title = \"gamma = \" + str(gamma) + \" gillSpacing=\"+str(i)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"capSurface\")\n",
    "        plt.ylabel(\"habitat\")\n",
    "\n",
    "    image_directory = \"Images/SVC/SVC Regions/gamma = \" + str(gamma) + \".png\"\n",
    "    print(image_directory)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_directory)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC kernels hyperparameter exploration\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2)\n",
    "\n",
    "#create a list of kernels and fit an SVC model for each\n",
    "kernels = ['rbf', 'poly', 'linear']\n",
    "\n",
    "for kernel in kernels:\n",
    "    svc_kernel = SVC(kernel = kernel, random_state = 42)\n",
    "    svc_kernel.fit(X_train,y_train)\n",
    "\n",
    "    #plot a decision region graph for each kernel\n",
    "    for i in range(2):\n",
    "        plt.subplot(2,1,i+1)\n",
    "        plot_decision_regions(X_test.values, y_test.values, clf = svc_kernel, legend = 2, feature_index = [0,2], filler_feature_values={1: i}, filler_feature_ranges={1:0.75})\n",
    "        title = \"kernel = \" + str(kernel) + \" gillSpacing=\"+str(i)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"capSurface\")\n",
    "        plt.ylabel(\"habitat\")\n",
    "\n",
    "    #save the plots as png\n",
    "    image_directory = \"Images/SVC/SVC Regions/kernel = \" + str(kernel) + \".png\"\n",
    "    print(image_directory)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_directory)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC C hyperparameter exploration\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2)\n",
    "\n",
    "#create a list of C values and fit an SVC model for each\n",
    "cs = [0.1,0.5,1,10,30]\n",
    "\n",
    "for c in cs:\n",
    "    svc_c = SVC(C = c, random_state = 42)\n",
    "    svc_c.fit(X_train,y_train)\n",
    "\n",
    "    #for each candidate value create a decision region plot\n",
    "    for i in range(2):\n",
    "        plt.subplot(2,1,i+1)\n",
    "        plot_decision_regions(X_test.values, y_test.values, clf = svc_c, legend = 2, feature_index = [0,2], filler_feature_values={1: i}, filler_feature_ranges={1:0.75})\n",
    "        title = \"C = \" + str(c) + \" gillSpacing=\"+str(i)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"capSurface\")\n",
    "        plt.ylabel(\"habitat\")\n",
    "\n",
    "    #save plots as png\n",
    "    image_directory = \"Images/SVC/SVC Regions/C = \" + str(c) + \".png\"\n",
    "    print(image_directory)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_directory)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make informed decisions about chosen candidate values for k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for SVC\n",
    "\n",
    "#create distribution of chosen hyperparamaters to be used in SVC\n",
    "gamma = [2,5,10,20,30]\n",
    "kernel = ['linear', 'rbf']\n",
    "c = [2,5,10,20,30]\n",
    "\n",
    "#create dictionary with distribution of chosen hyperparameters\n",
    "random_grid = {'gamma': gamma,\n",
    "               'kernel': kernel,\n",
    "               'C': c,\n",
    "}\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "#basline model to compare to when optimising\n",
    "svc = SVC(random_state=42,)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(uncorrelated_X, y, test_size=0.2)\n",
    "\n",
    "baseline_SVC = SVC(random_state = 42)\n",
    "\n",
    "baseline_SVC.fit(X_train, y_train)\n",
    "baseline_SVC_pred = baseline_SVC.predict(X_test)\n",
    "\n",
    "#find best scoring random hyperparameter combination\n",
    "SVC_random = RandomizedSearchCV(estimator = svc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1, scoring = 'accuracy')\n",
    "\n",
    "SVC_random.fit(X_train, y_train)\n",
    "best_random_values = SVC_random.best_params_\n",
    "\n",
    "print(\"\\n\", SVC_random.best_params_, \"\\n\")\n",
    "best_random_SVC = SVC_random.best_estimator_\n",
    "print(best_random_SVC)\n",
    "\n",
    "#predict using best random model and get model accuracy report\n",
    "best_pred = best_random_SVC.predict(X_test)\n",
    "\n",
    "#create a refined hyperparameter grid with values close to the best random estimator to look for further optimization\n",
    "\n",
    "param_grid = {\n",
    "    'gamma': list(range((best_random_values['gamma']-1),(best_random_values['gamma']+1))),\n",
    "    'kernel': [best_random_values['kernel']],\n",
    "    'C': list(range((best_random_values['C']-1),(best_random_values['C']+1))),\n",
    "}\n",
    "\n",
    "svc2 = SVC(random_state = 42)\n",
    "\n",
    "#find the best scoring model using the refined hyperparameter grid\n",
    "svc_grid = GridSearchCV(estimator = svc2, param_grid = param_grid, cv = 3, verbose=2, n_jobs = -1, scoring = 'accuracy')\n",
    "\n",
    "svc_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n\", svc_grid.best_params_, \"\\n\")\n",
    "best_grid_svc = svc_grid.best_estimator_\n",
    "print(best_grid_svc)\n",
    "\n",
    "#predict values using this model and show accuracy to compare models later\n",
    "best_pred2 = best_grid_svc.predict(X_test)\n",
    "\n",
    "print(\"\\n\", svc_grid.best_params_, \"\\n\")\n",
    "best_grid_svc = svc_grid.best_estimator_\n",
    "print(best_grid_svc)\n",
    "\n",
    "#predict values using this model and show accuracy to compare models later\n",
    "best_pred2 = best_grid_svc.predict(X_test)\n",
    "\n",
    "#create a figure to plot 3 confusion matrix for each iteration of the SVC model\n",
    "figure, axes = plt.subplots(1,3,figsize = (15,5))\n",
    "figure.suptitle(\"Confusion matrices of each model iteration\")\n",
    "\n",
    "#create confusion matrix and labels for clear plotting\n",
    "cf_matrix = confusion_matrix(y_test, baseline_SVC_pred)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "#show model accuracy report\n",
    "print(\"Baseline\\n\")\n",
    "print(classification_report(y_test,baseline_SVC_pred))\n",
    "\n",
    "print(cf_matrix)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix, annot = labels,fmt = '', cmap = 'Blues', ax = axes[0], cbar = False)\n",
    "\n",
    "print(\"Random Search\\n\")\n",
    "print(classification_report(y_test,best_pred))\n",
    "\n",
    "#create second confusion matrix and labels for clear plotting\n",
    "cf_matrix_2 = confusion_matrix(y_test, best_pred)\n",
    "\n",
    "print(cf_matrix_2)\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix_2.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix_2.flatten()/np.sum(cf_matrix_2)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix_2, annot = labels,fmt = '', cmap = 'Blues', ax = axes[1],cbar = False)\n",
    "\n",
    "print(\"Grid Search\\n\")\n",
    "print(classification_report(y_test,best_pred2))\n",
    "\n",
    "#create third confusion matrix and labels for clear plotting\n",
    "cf_matrix_3 = confusion_matrix(y_test, best_pred2)\n",
    "\n",
    "print(cf_matrix_3)\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix_3.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix_3.flatten()/np.sum(cf_matrix_3)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix_3, annot = labels,fmt = '', cmap = 'Blues', ax = axes[2])\n",
    "\n",
    "#save the plots as png\n",
    "plt.savefig(\"Images/SVC/Confusion Matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Model Comparison__ <br>\n",
    "The following cells contain the code for the receiver operating characteristic curve (ROC) & precision-recall curve (PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prediction probabilities as we used .predict for each algorithm earlier\n",
    "r_probs = [0 for _ in range(len(y_test))]   #for baseline\n",
    "knn_probs = best_grid_knn.predict_proba(X_test)\n",
    "rf_probs = best_grid_rf.predict_proba(X_test)\n",
    "svc_probs = best_grid_svc.decision_function(X_test)\n",
    "\n",
    "#remove negative values\n",
    "rf_probs = rf_probs[:, 1]\n",
    "knn_probs = knn_probs[:, 1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell for the ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the area under the roc curve\n",
    "r_auc = roc_auc_score(y_test, r_probs)\n",
    "knn_auc = roc_auc_score(y_test, knn_probs)\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "svc_auc = roc_auc_score(y_test, svc_probs)\n",
    "\n",
    "#calculate the values of points for the roc curve\n",
    "r_fpr, r_tpr, _ = roc_curve(y_test, r_probs)\n",
    "knn_fpr, knn_tpr, _ = roc_curve(y_test, knn_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "svc_fpr, svc_tpr, _ = roc_curve(y_test, svc_probs)\n",
    "\n",
    "#plot the curves using pyplot\n",
    "plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "plt.plot(r_fpr, r_tpr, linestyle='--', label='Random prediction (AUROC = %0.3f)' % r_auc)\n",
    "plt.plot(knn_fpr, knn_tpr, marker='.', label='KNN (AUROC = %0.3f)' % knn_auc)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.', label='Random Forest (AUROC = %0.3f)' % rf_auc)\n",
    "plt.plot(svc_fpr, svc_tpr, marker='.', label='SVM (auc = %0.3f)' % svc_auc)\n",
    "\n",
    "plt.title(\"ROC Curves for the algorithms\")\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"Images/ROC/ROC Curves\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell for PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate precision and the recall values for each algorithm at different thresholds\n",
    "knn_precision, knn_recall, thresholds = precision_recall_curve(y_test, knn_probs)\n",
    "rf_precision, rf_recall, thresholds = precision_recall_curve(y_test, rf_probs)\n",
    "svc_precision, svc_recall, thresholds = precision_recall_curve(y_test, svc_probs)\n",
    "\n",
    "#calculate the area under the each curve\n",
    "knn_auc_pr = auc(knn_recall, knn_precision)\n",
    "rf_auc_pr = auc(rf_recall, rf_precision)\n",
    "svc_auc_pr = auc(svc_recall, svc_precision)\n",
    "\n",
    "#line for baseline model\n",
    "random_pr = len(y_test[y_test==1]) / len(y_test)\n",
    "\n",
    "#plot the curves using pyplot\n",
    "plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "plt.plot([0,1], [random_pr, random_pr], linestyle='--', label='Random prediction')\n",
    "plt.plot(knn_recall, knn_precision, marker='.', label='KNN (AUCPR = %0.3f)' % knn_auc_pr)\n",
    "plt.plot(rf_recall, rf_precision, marker='.', label='Random Forest (AUCPR = %0.3f)' % rf_auc_pr)\n",
    "plt.plot(svc_recall, svc_precision, marker='.', label='SVC (AUCPR = %0.3f)' % svc_auc_pr)\n",
    "\n",
    "plt.title(\"PR Curves for the algorithms\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"Images/PR/PR Curves\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
